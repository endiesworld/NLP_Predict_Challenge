{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Clasification Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**Emmanuel Okoro**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### EDSA 2022 Classification Hackathon\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Our clients would like to know people's perception on climate change, whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received, which will increasing their insights and informing future marketing strategies.\n",
    "\n",
    "SWAT_Team_7 has been consulted to create a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "### Process\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine if a person believes in climate change or not, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246051de",
   "metadata": {},
   "source": [
    "### Comet_ml Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c916166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment with your api key\n",
    "# Every individual in this team is expected to edit the Experiment parameters with their respective comet_ml values\n",
    "# experiment = Experiment(\n",
    "#     api_key=\"emBEBYBp72gW5tfeZBSGftD0Y\",\n",
    "#     project_name=\"tweet-sentiment-analyzer\",\n",
    "#     workspace=\"emmanuelokoro\",\n",
    "#     log_code = True\n",
    "# )\n",
    "\n",
    "# experiment = Experiment(\n",
    "#     api_key=\"pRMxFxeNwUPYOyNGu3BPn91GY\",\n",
    "#     project_name=\"advanced-classification\",\n",
    "#     workspace=\"jakam\",\n",
    "#     log_code = True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c044ea",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "For this section, we carry out two different types of data analysis:\n",
    "- Univariate \\\n",
    "    i. non-graphical \\\n",
    "    ii. graphical \n",
    "- Multivariate \\\n",
    "    i. non-graphical \\\n",
    "    ii. graphical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e773ee3",
   "metadata": {},
   "source": [
    "#### Univariate Non-Graphical Analysis\n",
    "For this analysis, we are going to view dataset on the below checks:  \\\n",
    "    i.  Check for the presence of *null* values  \\\n",
    "    ii. Descriptive statistical values *mean, std, minimum, quatiles, maximum, and kurtosis*  \n",
    "    iii. Dataset data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data statistics\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254e20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types for all columns\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f855bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>15819.0</td>\n",
       "      <td>0.917504</td>\n",
       "      <td>0.836537</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <td>15819.0</td>\n",
       "      <td>501719.433656</td>\n",
       "      <td>289045.983132</td>\n",
       "      <td>6.0</td>\n",
       "      <td>253207.5</td>\n",
       "      <td>502291.0</td>\n",
       "      <td>753769.0</td>\n",
       "      <td>999888.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean            std  min       25%       50%  \\\n",
       "sentiment  15819.0       0.917504       0.836537 -1.0       1.0       1.0   \n",
       "tweetid    15819.0  501719.433656  289045.983132  6.0  253207.5  502291.0   \n",
       "\n",
       "                75%       max  \n",
       "sentiment       1.0       2.0  \n",
       "tweetid    753769.0  999888.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data statistics\n",
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b05422a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0.122976\n",
       "tweetid     -1.193356\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf02c5b",
   "metadata": {},
   "source": [
    "From the above analysis thus far, it is evidence that we only have two numeric colunms. \n",
    "However we suspect that one of these columns(tweetid) contains unique values in each row, while the other column(sentiment) from the name, we infere that it is our label, hence contains a minimum of two different values.\n",
    "\n",
    "To confirm the above, we write a function that takes in a dataframe and a column-id, to give an output which is the number of unique values in the column as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e95c1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_val(df, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column name, \n",
    "        and ouputs an interger, which is the number of unique \n",
    "        values in the column.\n",
    "    \"\"\"\n",
    "    return df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22e6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of unique values in the sentiment column is : 4\n"
     ]
    }
   ],
   "source": [
    "# Check the numbers of unique values for the sentiment column\n",
    "print(f'The numbers of unique values in the sentiment column is : {unique_val(df_train, \"sentiment\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e48c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of unique values in the tweetid column is : 15819\n"
     ]
    }
   ],
   "source": [
    "# Check the numbers of unique values for the tweetid column\n",
    "print(f'The numbers of unique values in the tweetid column is : {unique_val(df_train, \"tweetid\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e2880",
   "metadata": {},
   "source": [
    "From the above results, the sentiment column contains four different unique values, and we want to see how this values\n",
    "are distributed in the column.\n",
    "To achieve this, we write a function called *unique_val_count*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80cd6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_val_count(df, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column name, \n",
    "        and ouputs a dictionary, which contains the unique values as a key, and the numbers as values.\n",
    "    \"\"\"\n",
    "    distribution = {}\n",
    "    unique_vals = df[col].unique()\n",
    "    for val in unique_vals:\n",
    "        distribution[val] = df[df[col] == val][col].count()\n",
    "    \n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ddf06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8530, 2: 3640, 0: 2353, -1: 1296}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val_count(df_train, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8fec5",
   "metadata": {},
   "source": [
    "### Check for presence of non-alphanumeric words\n",
    "\n",
    "This task will be done in the data engineering section, after we have removed all stop-words and punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd562db5",
   "metadata": {},
   "source": [
    "### Univariate graphical inspection of data\n",
    "For this analysis, we view the individual colunms using histogram plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3f47bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot of label classes\n",
    "fig,ax = plt.subplots()\n",
    "df_train['sentiment'].value_counts().plot(kind = 'bar', facecolor='g', alpha=0.65)\n",
    "ax.set_xlabel('Sentiments')\n",
    "ax.set_ylabel('Sentiments count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74b341",
   "metadata": {},
   "source": [
    "# PUT IN WORD CLOUD BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1525812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b34f68",
   "metadata": {},
   "source": [
    "## Also include findings from world cloud in EDA summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f2a7d",
   "metadata": {},
   "source": [
    "### EDA summary\n",
    "- The dataset contains three columns (sentiments, message and tweetid)\n",
    "- Sentiments and tweetid are of numeric data type, while message is non-numeric\n",
    "- tweetid is a clumn with uniques values acreoss the entire rows of the dataset\n",
    "- sentiments columns contains for different unique values (-1, 0, 1 &2) with different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de51df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at feature distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ced808",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "### Removing Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba0d8c",
   "metadata": {},
   "source": [
    "For the given dataset, we identified that the *message* column contains the novel tweet for each userid, which we are espected to classify. \n",
    "For us to proceed we have to carry out cleaning on this messages. This cleaning will be achieved through:\n",
    "* identify and remove web-urls from the main message \n",
    "* idendify and remove words started with '#'\n",
    "* idendify and remove words started with '@'\n",
    "* making everything lower case\n",
    "* removing punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab1ea8",
   "metadata": {},
   "source": [
    "#### Remove web-url from message\n",
    "\n",
    "We write a function called *delete_url*. This function uses regex to identify web-url in a column and remove same from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_url(data, col):\n",
    "    \"\"\"\n",
    "        Accepts a dataframe and col., removes web urls from the col.\n",
    "        returns a new dataframe \n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    subs_url = ''\n",
    "    df[col] = df[col].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98fa8207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_train = delete_url(df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!?  via @mashable\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the above operation was successful \n",
    "new_df_train['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59692724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['message'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b3c36",
   "metadata": {},
   "source": [
    "### Remove '#' and '@' words\n",
    "\n",
    "We write a function *delete_tags*, to identify and remove words started with '#' and '@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92a0f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tags(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a col, removes all words started with '#' and '@' in the column,\n",
    "        and returns a new dataframe\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    pattern_tags = r'#\\w+[#?]'\n",
    "    pattern_2 = r'@\\w+'\n",
    "    subs_tag = ''\n",
    "    df[col] = df[col].replace(to_replace = pattern_tags, value = subs_tag, regex = True)\n",
    "    df[col] = df[col].replace(to_replace = pattern_2, value = subs_tag, regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8422fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT : Researchers say we have three years to ac...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>WIRED : 2016 was a pivotal year in the war on...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : It's 2016, and a racist, sexist, climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT : Researchers say we have three years to ac...   698562\n",
       "3          1   WIRED : 2016 was a pivotal year in the war on...   573736\n",
       "4          1  RT : It's 2016, and a racist, sexist, climate ...   466954"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_train = delete_tags(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ec814",
   "metadata": {},
   "source": [
    "### Convert capitalized words to lowercase words\n",
    "\n",
    "We write a function *word_converter* to convert capitalized words to lowercase words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcb93891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_converter(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and col, converts all capitalized words in the column to lowercase,\n",
    "        and returns a new dataframe.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    df[col] = df[col].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ac78c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt : researchers say we have three years to ac...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired : 2016 was a pivotal year in the war on...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt : it's 2016, and a racist, sexist, climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesn't think carbon di...   625221\n",
       "1          1  it's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  rt : researchers say we have three years to ac...   698562\n",
       "3          1   wired : 2016 was a pivotal year in the war on...   573736\n",
       "4          1  rt : it's 2016, and a racist, sexist, climate ...   466954"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with all words in the message column converted to its lowercase form\n",
    "new_df_train = word_converter(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f51a4",
   "metadata": {},
   "source": [
    "### Remove punctuation\n",
    "\n",
    "We write a function *remove_punc* that uses the string package from python to remove punctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87a4a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column, uses python string package to identify and remove all\n",
    "        punctions in the column. It returns a new dataframe\n",
    "    \"\"\"\n",
    "    def operation(post):\n",
    "        return ''.join([l for l in post if l not in string.punctuation])\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    df[col] = df[col].apply(operation)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0deb07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
       "1          1  its not like we lack evidence of anthropogenic...   126103\n",
       "2          2  rt  researchers say we have three years to act...   698562\n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736\n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_train = remove_punc(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb8adf",
   "metadata": {},
   "source": [
    "### Remove new lines (\\n)  and 'rt' from the start of any words\n",
    "\n",
    "We noticed that some words start with '\\n' and this is a short form for new line in programming, words started with \\n looses its original meaning.\n",
    "\n",
    "Hence we write a function remove_new_line to execute this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69ee9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_new_line(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, returns a new dataframe with a new column void of new line command\n",
    "    \"\"\"\n",
    "\n",
    "    def operation(text):\n",
    "        result = re.sub(\"\\n\", \"\", text)\n",
    "        result = re.sub(\"rt\", \"\", result)\n",
    "        return result\n",
    "\n",
    "    df = data.copy()\n",
    "    \n",
    "    df[col] = df[col].apply(operation)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7548016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>its 2016 and a racist sexist climate change ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
       "1          1  its not like we lack evidence of anthropogenic...   126103\n",
       "2          2    researchers say we have three years to act o...   698562\n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736\n",
       "4          1    its 2016 and a racist sexist climate change ...   466954"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_train = remove_new_line(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa36e01",
   "metadata": {},
   "source": [
    "### Tokenisation\n",
    "\n",
    "We write a function *tokenizer* to tokenize the words in the message column and store same in a new column named *message_tok*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "897e0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a col, creates a new column to store the tokenized words\n",
    "        in the inputed column, and returns a new dataframe.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    tokeniser = TreebankWordTokenizer()\n",
    "    df['message_tok'] = df[col].apply(tokeniser.tokenize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea5182f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[researchers, say, we, have, three, years, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>its 2016 and a racist sexist climate change ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[its, 2016, and, a, racist, sexist, climate, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2    researchers say we have three years to act o...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1    its 2016 and a racist sexist climate change ...   466954   \n",
       "\n",
       "                                         message_tok  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...  \n",
       "2  [researchers, say, we, have, three, years, to,...  \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...  \n",
       "4  [its, 2016, and, a, racist, sexist, climate, c...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold the tokens from message column\n",
    "new_df_train = tokenizer(new_df_train, 'message')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c845c",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "We write a function *stem_words* to transform all words in the *message_tok* column to its root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4957f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, converts the words in the column to it root form,\n",
    "        with the aid of SnowballStemmer class from the nltk package.\n",
    "        Returns a new dataframe with an additional column \"message_stem\"\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    def operation(words, stemmer):\n",
    "        return [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    df = data.copy()\n",
    "    df[\"message_stem\"] = df[col].apply(operation, args=(stemmer, ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09d2c7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[researchers, say, we, have, three, years, to,...</td>\n",
       "      <td>[research, say, we, have, three, year, to, act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>its 2016 and a racist sexist climate change ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[its, 2016, and, a, racist, sexist, climate, c...</td>\n",
       "      <td>[it, 2016, and, a, racist, sexist, climat, cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2    researchers say we have three years to act o...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1    its 2016 and a racist sexist climate change ...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [researchers, say, we, have, three, years, to,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [its, 2016, and, a, racist, sexist, climate, c...   \n",
       "\n",
       "                                        message_stem  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...  \n",
       "2  [research, say, we, have, three, year, to, act...  \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...  \n",
       "4  [it, 2016, and, a, racist, sexist, climat, cha...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_train = stem_words(new_df_train, 'message_tok')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c55afc",
   "metadata": {},
   "source": [
    "### Larmming\n",
    "\n",
    "We write a function *lam_words* to transform all words in the *message_tok* column to its root form using Lemmatization, to enable us acrter for the shortfall in stemming above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "148e0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lam_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes in a dataframe and a column, converts the words in the column to it root form,\n",
    "        with the aid of WordNetLemmatizer class from the nltk package.\n",
    "        Returns a new dataframe with an additional column \"message_lam\"\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def operation(words, lemmatizer):\n",
    "        return [lemmatizer.lemmatize(word) for word in words] \n",
    "    df = data.copy()\n",
    "    df[\"message_lam\"] = df[col].apply(operation, args=(lemmatizer, ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea6ae293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[researchers, say, we, have, three, years, to,...</td>\n",
       "      <td>[research, say, we, have, three, year, to, act...</td>\n",
       "      <td>[researcher, say, we, have, three, year, to, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "      <td>[wired, 2016, wa, a, pivotal, year, in, the, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>its 2016 and a racist sexist climate change ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[its, 2016, and, a, racist, sexist, climate, c...</td>\n",
       "      <td>[it, 2016, and, a, racist, sexist, climat, cha...</td>\n",
       "      <td>[it, 2016, and, a, racist, sexist, climate, ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2    researchers say we have three years to act o...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1    its 2016 and a racist sexist climate change ...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [researchers, say, we, have, three, years, to,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [its, 2016, and, a, racist, sexist, climate, c...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...   \n",
       "2  [research, say, we, have, three, year, to, act...   \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...   \n",
       "4  [it, 2016, and, a, racist, sexist, climat, cha...   \n",
       "\n",
       "                                         message_lam  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...  \n",
       "2  [researcher, say, we, have, three, year, to, a...  \n",
       "3  [wired, 2016, wa, a, pivotal, year, in, the, w...  \n",
       "4  [it, 2016, and, a, racist, sexist, climate, ch...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_train = lam_words(new_df_train, 'message_tok')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4510e4f",
   "metadata": {},
   "source": [
    "### Remove stop words\n",
    "Stop words are words which do not contain important significance to be used in Search Queries. \n",
    "We write a function *remove_stop_word*, that removes stop words in a speified column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3ebade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data, col):\n",
    "    \"\"\"\n",
    "        Takes a dataframe and a column, creates a new dataframe with a new column no_stop_word from the input\n",
    "        dataframe and column, returns the new column\n",
    "    \"\"\"\n",
    "    def operation(toks):\n",
    "        new_toks = [tok for tok in toks if tok not in stopwords.words('english')]\n",
    "        return new_toks\n",
    "    \n",
    "    df = data.copy()\n",
    "    df['no_stop_word'] = df[col].apply(operation)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5f6dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "      <th>no_stop_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[researchers, say, we, have, three, years, to,...</td>\n",
       "      <td>[research, say, we, have, three, year, to, act...</td>\n",
       "      <td>[researcher, say, we, have, three, year, to, a...</td>\n",
       "      <td>[researcher, say, three, year, act, climate, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "      <td>[wired, 2016, wa, a, pivotal, year, in, the, w...</td>\n",
       "      <td>[wired, 2016, wa, pivotal, year, war, climate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>its 2016 and a racist sexist climate change ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[its, 2016, and, a, racist, sexist, climate, c...</td>\n",
       "      <td>[it, 2016, and, a, racist, sexist, climat, cha...</td>\n",
       "      <td>[it, 2016, and, a, racist, sexist, climate, ch...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2    researchers say we have three years to act o...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1    its 2016 and a racist sexist climate change ...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [researchers, say, we, have, three, years, to,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [its, 2016, and, a, racist, sexist, climate, c...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...   \n",
       "2  [research, say, we, have, three, year, to, act...   \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...   \n",
       "4  [it, 2016, and, a, racist, sexist, climat, cha...   \n",
       "\n",
       "                                         message_lam  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...   \n",
       "2  [researcher, say, we, have, three, year, to, a...   \n",
       "3  [wired, 2016, wa, a, pivotal, year, in, the, w...   \n",
       "4  [it, 2016, and, a, racist, sexist, climate, ch...   \n",
       "\n",
       "                                        no_stop_word  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [like, lack, evidence, anthropogenic, global, ...  \n",
       "2  [researcher, say, three, year, act, climate, c...  \n",
       "3  [wired, 2016, wa, pivotal, year, war, climate,...  \n",
       "4  [2016, racist, sexist, climate, change, denyin...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column from message_lam void of stop words\n",
    "new_df_train = remove_stop_words(new_df_train, 'message_lam')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0135cec",
   "metadata": {},
   "source": [
    "### Check for the presence of noise as non-alphanumeric worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45206759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_type_checker(data, col):\n",
    "    alphanum_count = 0 \n",
    "    non_alphanum_count = 0\n",
    "    \n",
    "    def operation(str_list , alphanum_count ,non_alphanum_count):\n",
    "        alphanum = alphanum_count\n",
    "        non_aphanum = non_alphanum_count\n",
    "#         print(f'past row values: {(alphanum, non_aphanum)}') # for testing \n",
    "        for strg in str_list:\n",
    "            if strg.isalnum():\n",
    "                alphanum = alphanum + 1\n",
    "            else:\n",
    "                non_aphanum = non_aphanum + 1\n",
    "        \n",
    "        return (alphanum ,non_aphanum)\n",
    "    \n",
    "    for label, sr in data.iterrows():\n",
    "        (alphanum_count, non_alphanum_count) = operation(sr[col] , alphanum_count, non_alphanum_count)\n",
    "#         Uncomment the codes below for testing of this function\n",
    "#         print(f'accumulated values: {(alphanum_count, non_alphanum_count)}') \n",
    "#         if label == 20:\n",
    "#             break\n",
    "    \n",
    "    return (alphanum_count, non_alphanum_count)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae9a9723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154708, 9687)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(alphanumeric, non_alphanumeric) = word_type_checker(new_df_train, 'no_stop_word')\n",
    "(alphanumeric, non_alphanumeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78213bc",
   "metadata": {},
   "source": [
    "### Convert processed words to corpus\n",
    "\n",
    "Before we can transform the words in numeric type, for each column we have to remove the delimeters introduced during tokennization. This process is needed to enable us form a **corpus**.\n",
    "To achieve this, we write a function **form_corpus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42c773f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_corpus(data, col):\n",
    "    \"\"\"\n",
    "        This function takes in a dataframe and a column with tokenized text, \n",
    "        returns a new dataframe with an additional column(de_tok), which is made up of all words in the inserted colunm\n",
    "        but void of delimeters.\n",
    "    \"\"\"\n",
    "    def operation(tok_list):\n",
    "        string = ' '.join(tok_list)\n",
    "        return string\n",
    "    df = data.copy()\n",
    "    df['de_tok'] = df[col].apply(operation)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38167fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_tok</th>\n",
       "      <th>message_stem</th>\n",
       "      <th>message_lam</th>\n",
       "      <th>no_stop_word</th>\n",
       "      <th>de_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evid, of, anthropoge...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act o...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[researchers, say, we, have, three, years, to,...</td>\n",
       "      <td>[research, say, we, have, three, year, to, act...</td>\n",
       "      <td>[researcher, say, we, have, three, year, to, a...</td>\n",
       "      <td>[researcher, say, three, year, act, climate, c...</td>\n",
       "      <td>researcher say three year act climate change i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired  2016 was a pivotal year in the war on ...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[wired, 2016, was, a, pivotal, year, in, the, ...</td>\n",
       "      <td>[wire, 2016, was, a, pivot, year, in, the, war...</td>\n",
       "      <td>[wired, 2016, wa, a, pivotal, year, in, the, w...</td>\n",
       "      <td>[wired, 2016, wa, pivotal, year, war, climate,...</td>\n",
       "      <td>wired 2016 wa pivotal year war climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>its 2016 and a racist sexist climate change ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[its, 2016, and, a, racist, sexist, climate, c...</td>\n",
       "      <td>[it, 2016, and, a, racist, sexist, climat, cha...</td>\n",
       "      <td>[it, 2016, and, a, racist, sexist, climate, ch...</td>\n",
       "      <td>[2016, racist, sexist, climate, change, denyin...</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2    researchers say we have three years to act o...   698562   \n",
       "3          1   wired  2016 was a pivotal year in the war on ...   573736   \n",
       "4          1    its 2016 and a racist sexist climate change ...   466954   \n",
       "\n",
       "                                         message_tok  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [researchers, say, we, have, three, years, to,...   \n",
       "3  [wired, 2016, was, a, pivotal, year, in, the, ...   \n",
       "4  [its, 2016, and, a, racist, sexist, climate, c...   \n",
       "\n",
       "                                        message_stem  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evid, of, anthropoge...   \n",
       "2  [research, say, we, have, three, year, to, act...   \n",
       "3  [wire, 2016, was, a, pivot, year, in, the, war...   \n",
       "4  [it, 2016, and, a, racist, sexist, climat, cha...   \n",
       "\n",
       "                                         message_lam  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...   \n",
       "2  [researcher, say, we, have, three, year, to, a...   \n",
       "3  [wired, 2016, wa, a, pivotal, year, in, the, w...   \n",
       "4  [it, 2016, and, a, racist, sexist, climate, ch...   \n",
       "\n",
       "                                        no_stop_word  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [like, lack, evidence, anthropogenic, global, ...   \n",
       "2  [researcher, say, three, year, act, climate, c...   \n",
       "3  [wired, 2016, wa, pivotal, year, war, climate,...   \n",
       "4  [2016, racist, sexist, climate, change, denyin...   \n",
       "\n",
       "                                              de_tok  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1    like lack evidence anthropogenic global warming  \n",
       "2  researcher say three year act climate change i...  \n",
       "3      wired 2016 wa pivotal year war climate change  \n",
       "4  2016 racist sexist climate change denying bigo...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column from no_stop_word void of delimeters\n",
    "new_df_train = form_corpus(new_df_train, 'no_stop_word')\n",
    "new_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12b92c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>de_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researcher say three year act climate change i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wired 2016 wa pivotal year war climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 racist sexist climate change denying bigo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             de_tok\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...\n",
       "1          1    like lack evidence anthropogenic global warming\n",
       "2          2  researcher say three year act climate change i...\n",
       "3          1      wired 2016 wa pivotal year war climate change\n",
       "4          1  2016 racist sexist climate change denying bigo..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop every other columns except sentiment and de_tok columns\n",
    "df_train_reduced = new_df_train[['sentiment', 'de_tok']]\n",
    "df_train_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbc020",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "- **Downsampling the majority class**\n",
    "- **Upsampling the minority class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554a327",
   "metadata": {},
   "source": [
    "To achieve the above, we write a multipurpose function called **resampler**, which we can use for both **Downsampling** and **Upsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d670945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampler(df_list, n_sample, replace=False):\n",
    "    \"\"\"\n",
    "        This function takes a list of dataframe, the size which we intend to resize all dataframes in the list to, and\n",
    "        an optional replace[bool] value, which is set to True for upsampling\n",
    "        It returns a tuple of new dataframes with sizes equivalent to the value for n_sample\n",
    "    \"\"\"\n",
    "    \n",
    "    def operation(df):\n",
    "        downsampled_df = resample(df,\n",
    "                          replace= replace, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=n_sample, # match number in minority class\n",
    "                          random_state= RANDOM_STATE) # reproducible results\n",
    "        return downsampled_df\n",
    "    \n",
    "    resampled_dfs = tuple(map(operation , df_list))\n",
    "    \n",
    "    return resampled_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6127d",
   "metadata": {},
   "source": [
    "#### Create new dataframes\n",
    "    We create new dataframes basedd on sentiment type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55cc617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = df_train_reduced[df_train_reduced['sentiment'] == 1]\n",
    "anti = df_train_reduced[df_train_reduced['sentiment'] == -1]\n",
    "neutral = df_train_reduced[df_train_reduced['sentiment'] == 0]\n",
    "info =  df_train_reduced[df_train_reduced['sentiment'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8489646",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20b09c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1296\n",
       " 2    1296\n",
       " 0    1296\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample pro, infor and neutral dataframe \n",
    "(pro_df, info_df, neut_df) = resampler([pro,info,neutral], len(anti))\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "downsampled = pd.concat([pro_df, info_df, neut_df,anti])\n",
    "\n",
    "# Check new class counts\n",
    "downsampled['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe38e63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the downsampled dataframe\n",
    "original_height = [len(pro), len(neutral), len(info), len(anti)]\n",
    "downsampled_heights = [len(downsampled[downsampled['sentiment']==1]),len(downsampled[downsampled['sentiment']==0]),\n",
    "                      len(downsampled[downsampled['sentiment']==2]) ,len(downsampled[downsampled['sentiment']==-1])]\n",
    "\n",
    "# Get all possible labels\n",
    "labels = downsampled['sentiment'].unique()\n",
    "plt.bar(labels,original_height,color='grey')\n",
    "plt.bar(labels,downsampled_heights,color='orange')\n",
    "plt.xticks(labels,[1,0, 2, -1])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.xlabel(\"Sentiments\")\n",
    "plt.legend(['original','resampled'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17527320",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef8aeef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    8530\n",
       " 0    8530\n",
       "-1    8530\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsample info, neutral and anti dataframe \n",
    "(up_info_df, up_neut_df, up_anti_df) = resampler([info,neutral, anti], len(pro), True)\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "upsampled = pd.concat([pro, up_info_df, up_neut_df,up_anti_df])\n",
    "\n",
    "# Check new class counts\n",
    "upsampled['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f687594b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the upnsampled dataframe\n",
    "original_height = [len(pro), len(neutral), len(info), len(anti)]\n",
    "upsampled_heights = [len(upsampled[upsampled['sentiment']==1]),len(upsampled[upsampled['sentiment']==0]),\n",
    "                      len(upsampled[upsampled['sentiment']==2]) ,len(upsampled[upsampled['sentiment']==-1])]\n",
    "\n",
    "# Get all possible labels\n",
    "labels = upsampled['sentiment'].unique()\n",
    "plt.bar(labels,upsampled_heights,color='orange')\n",
    "plt.bar(labels,original_height,color='grey')\n",
    "plt.xticks(labels,[1,0, 2, -1])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.xlabel(\"Sentiments\")\n",
    "plt.legend(['resampled','original'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c900d343",
   "metadata": {},
   "source": [
    "### Data container\n",
    "\n",
    "From the above two operations, we now have three different data set :\n",
    "- **df_train_reduced** (original data set)\n",
    "- **downsampled** (down sampled data set)\n",
    "- **upsampled** (up sampled data set)\n",
    "\n",
    "We then proceed to store these three different data set in a data container named **DataSetSelector**, which enables us select a particular type of data set at a particular time using their respective index numbers (0,1,2), and storing same in a variable called **data_set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25d1896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataSetSelector, store the data sets, and define data_set, which contains the selected data set\n",
    "DataSetSelector = [df_train_reduced, downsampled, upsampled]\n",
    "\n",
    "data_set = DataSetSelector[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0efc0",
   "metadata": {},
   "source": [
    "### Transforming text into numbers\n",
    "\n",
    "- CounterVectorizer\n",
    "- TfidfVectorizer\n",
    "\n",
    "Most models do not work well with text, hence the need to convert our text into numbers. To execute this task and more, we can use **CountVectorizer** or **TfidfVectorizer** packages from sklearn library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbb771",
   "metadata": {},
   "source": [
    "#### CountVectorizer\n",
    "**CountVectorizer** has some **hyperparameters** which we can asign desired values to while initialising. \n",
    "The **hyperparameters** that we shall be tunning for these work are: \n",
    "\n",
    "- **max_df** :  When building the vocabulary ignore terms that have a document frequency strictly higher than the                     given threshold (corpus-specific stop words). If float, the parameter represents a proportion of                       documents,integer absolute counts.This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **min_df** :  When building the vocabulary ignore terms that have a document frequency strictly lower than the given                 threshold. This value is also called cut-off in the literature. If float, the parameter represents a                   proportion of documents, integer absolute counts.This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **max_features**: If not None, build a vocabulary that only consider the top max_features ordered by term frequency                     across the corpus. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **analyzer**: Whether the feature should be made of word n-gram or character n-grams. Option ‘char_wb’ creates                       character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with                 space.\n",
    "\n",
    "- **ngram_range**: The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to                    be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92c4c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an object of CountVectorizer\n",
    "count_vector = CountVectorizer(max_features=20000,analyzer='word', ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816157bf",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer\n",
    "**TfidfVectorizer** has some **hyperparameters** which we can asign desired values to while initialising. \n",
    "The **hyperparameters** that we shall be tunning for these work are: \n",
    "\n",
    "- **max_df** :  When building the vocabulary ignore terms that have a document frequency strictly higher than the                     given threshold (corpus-specific stop words). If float, the parameter represents a proportion of                       documents,integer absolute counts.This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **min_df** :  When building the vocabulary ignore terms that have a document frequency strictly lower than the given                 threshold. This value is also called cut-off in the literature. If float, the parameter represents a                   proportion of documents, integer absolute counts.This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **max_features**: If not None, build a vocabulary that only consider the top max_features ordered by term frequency                     across the corpus. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **analyzer**: Whether the feature should be made of word n-gram or character n-grams. Option ‘char_wb’ creates                       character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with                 space.\n",
    "\n",
    "- **ngram_range**: The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to                    be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91a506db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS VECTORIZER USING THE DEFAULT max_features hyperparameter setting\n",
    "# Initialize an object of TfidfVectorizer\n",
    "tfidf_vector = TfidfVectorizer( analyzer='word', ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4142a99",
   "metadata": {},
   "source": [
    "### Vectorizer Countainer\n",
    "\n",
    "We proceed to store the two vectorizers (CountVectorizer and TFidfVecorizer ) in a container( python list) named **VectorizerSelector**, which enables us to use index number (0,1), to select any vectorizer of choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c55ea19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VectorizerSeelector, a list of defined vectorizer, and selects the desired vectorizer with index number,\n",
    "# store the selected vectorizer in a variable named vector.\n",
    "\n",
    "VectorizerSelector = [count_vector , tfidf_vector]\n",
    "\n",
    "vector = VectorizerSelector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa2012",
   "metadata": {},
   "source": [
    "### Data Transformation \n",
    "\n",
    "We proceed to transform the features of the data set (**data_set**), with our choosen vectorizer **vector**, and store the transformed \n",
    "data in a variable called X_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "584fc9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34120, 20000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and Transform the de_tok column fit_transform method\n",
    "X_count = vector.fit_transform(data_set['de_tok'].values.astype(str))\n",
    "X_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951dbbe",
   "metadata": {},
   "source": [
    "#### Extract dependant for data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec762ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the dependant variable into a variable\n",
    "y = data_set['sentiment']\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ade51fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See feature names\n",
    "# vect_df.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f84351e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52905e3",
   "metadata": {},
   "source": [
    "### Convert vectorised data set back to dataframe form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe66104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>004</th>\n",
       "      <th>004 change</th>\n",
       "      <th>020</th>\n",
       "      <th>020 38</th>\n",
       "      <th>02after</th>\n",
       "      <th>02after trump</th>\n",
       "      <th>0bamas</th>\n",
       "      <th>0bamas tie</th>\n",
       "      <th>0c</th>\n",
       "      <th>0c swings</th>\n",
       "      <th>...</th>\n",
       "      <th>スタリん時代のソ連や毛沢東の文化大革命並のサイエンスに政治的介入だ どうなる米国</th>\n",
       "      <th>報告書は</th>\n",
       "      <th>報告書は 欧州が最も大きく地球温暖化の影響を受けていると警告しています</th>\n",
       "      <th>欧州が最も大きく地球温暖化の影響を受けていると警告しています</th>\n",
       "      <th>気候変動との表現を削除しないと予算を貰えない</th>\n",
       "      <th>気候変動との表現を削除しないと予算を貰えない と通知した</th>\n",
       "      <th>申請書のアブストラクトに</th>\n",
       "      <th>申請書のアブストラクトに climate</th>\n",
       "      <th>米国政府はある研究者に連絡して</th>\n",
       "      <th>米国政府はある研究者に連絡して 申請書のアブストラクトに</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   004  004 change  020  020 38  02after  02after trump  0bamas  0bamas tie  \\\n",
       "0    0           0    0       0        0              0       0           0   \n",
       "1    0           0    0       0        0              0       0           0   \n",
       "2    0           0    0       0        0              0       0           0   \n",
       "3    0           0    0       0        0              0       0           0   \n",
       "4    0           0    0       0        0              0       0           0   \n",
       "\n",
       "   0c  0c swings  ...  スタリん時代のソ連や毛沢東の文化大革命並のサイエンスに政治的介入だ どうなる米国  報告書は  \\\n",
       "0   0          0  ...                                         0     0   \n",
       "1   0          0  ...                                         0     0   \n",
       "2   0          0  ...                                         0     0   \n",
       "3   0          0  ...                                         0     0   \n",
       "4   0          0  ...                                         0     0   \n",
       "\n",
       "   報告書は 欧州が最も大きく地球温暖化の影響を受けていると警告しています  欧州が最も大きく地球温暖化の影響を受けていると警告しています  \\\n",
       "0                                    0                               0   \n",
       "1                                    0                               0   \n",
       "2                                    0                               0   \n",
       "3                                    0                               0   \n",
       "4                                    0                               0   \n",
       "\n",
       "   気候変動との表現を削除しないと予算を貰えない  気候変動との表現を削除しないと予算を貰えない と通知した  申請書のアブストラクトに  \\\n",
       "0                       0                             0             0   \n",
       "1                       0                             0             0   \n",
       "2                       0                             0             0   \n",
       "3                       0                             0             0   \n",
       "4                       0                             0             0   \n",
       "\n",
       "   申請書のアブストラクトに climate  米国政府はある研究者に連絡して  米国政府はある研究者に連絡して 申請書のアブストラクトに  \n",
       "0                     0                0                             0  \n",
       "1                     0                0                             0  \n",
       "2                     0                0                             0  \n",
       "3                     0                0                             0  \n",
       "4                     0                0                             0  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.DataFrame(data=X_count.toarray(),columns = vector.get_feature_names())\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb9f7b",
   "metadata": {},
   "source": [
    "### Spliting of data set\n",
    "\n",
    "Before we proceed to modelling, we have to split our data set into two sets (Training and Testing), to enable us internally evaluate the respective performance of our models. to achive this, we make use of sklearn **train_test_split** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5df39720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and testing data \n",
    "X_train, X_test, y_train, y_test = train_test_split(model_df, y, test_size=0.3, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad7bf5",
   "metadata": {},
   "source": [
    "### Model and model evaluation\n",
    "\n",
    "We write a function **model_eval**, that uses the training and test features and labels data set generated above, to train a model, make prediction with the model, and output the models performance with the aid of **classification_report** from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "873de8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model):\n",
    "    \"\"\"\n",
    "        This function accepts a model as an input, train and make predictions with the model, using the train and test\n",
    "        data set generated above, and ouput the trained model and the model's performance as a tuple.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return (model, classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8fee48",
   "metadata": {},
   "source": [
    "### Tunning models\n",
    "\n",
    "For this purpose we will use sklearn's **GridSearchCV**. This procedure allows us to specify a set of possible parameters for a specific model. GridSearchCV will then go through those parameters and try every possible combination of them (kind of like it's working through a grid in a systematic way - that's where the name comes from). GridSearchCV will then return the combination of parameters that resulted in a model with the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b9364",
   "metadata": {},
   "source": [
    "### Logistics Regression\n",
    "We proceed to create an instance of **Logistics Regression model** and manually set our desired hyperparameter\n",
    "#### Instanciate Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.98      0.97      2620\n",
      "           0       0.87      0.94      0.90      2458\n",
      "           1       0.89      0.75      0.81      2576\n",
      "           2       0.88      0.93      0.90      2582\n",
      "\n",
      "    accuracy                           0.90     10236\n",
      "   macro avg       0.90      0.90      0.90     10236\n",
      "weighted avg       0.90      0.90      0.90     10236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate a logistic regression model\n",
    "logreg_model = LogisticRegression(multi_class='ovr')\n",
    "\n",
    "# Train, predict and evaluate model performance \n",
    "(logreg_model, model_per) = model_eval(logreg_model)\n",
    "\n",
    "# Print model classification report\n",
    "print(\"\\n\\nClassification Report:\\n\\n\",model_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003d75c",
   "metadata": {},
   "source": [
    "#### RandomForest Classification Model\n",
    "\n",
    "We proceed to create an instance of **RandomForestClassifier model** and manually set our desired hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7dffd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98      2620\n",
      "           0       0.84      0.96      0.90      2458\n",
      "           1       0.93      0.72      0.81      2576\n",
      "           2       0.89      0.95      0.92      2582\n",
      "\n",
      "    accuracy                           0.90     10236\n",
      "   macro avg       0.91      0.91      0.90     10236\n",
      "weighted avg       0.91      0.90      0.90     10236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instanciate a RandomForestClassification model\n",
    "randomF_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train, predict and evaluate model performance \n",
    "(randomF_model, model_per) = model_eval(randomF_model)\n",
    "\n",
    "# Print model classification report\n",
    "print(\"\\n\\nClassification Report:\\n\\n\",model_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faaf07a",
   "metadata": {},
   "source": [
    "### SVM Model\n",
    "We proceed to create an instance of **SVM model** and create a list for each hyperparameter settings that we may be interested in seting, storing these list in a python dictionary, which we will then pass into sklearn GridSearch, which is a library from sklearn used in determining the best hyperparameter tunning for the inputed model passed into it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc741b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Support Vector Machine model\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "\n",
    "# Create and store hyperparameters values\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "# Store hyperparameters in a dictionary\n",
    "parameters = {\n",
    "    'C' : Cs,\n",
    "    'gamma' : gammas\n",
    "}\n",
    "\n",
    "# Instanciate a GridsearchCV and train same with \n",
    "svc_model = GridSearchCV(svc, parameters)\n",
    "\n",
    "# Train, predict and evaluate model performance \n",
    "(svc_model, model_per) = model_eval(svc_model)\n",
    "\n",
    "# Print model classification report\n",
    "print(\"\\n\\nClassification Report:\\n\\n\",model_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "### Test data set ( for kaggle submission )\n",
    "\n",
    "To enable us make prediction with our model, we have to import the **test** dataset and execute all data engineering operation executed on the **train** dataset.\n",
    "\n",
    "These activities are: \n",
    "- **delete urls**\n",
    "- **delete tags**\n",
    "- **convert words to lowercases**\n",
    "- **remove punctions**\n",
    "- **remove newlines**\n",
    "- **tokenize**\n",
    "- **stemming**\n",
    "- **larmming**\n",
    "- **remove stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and view the first 5 rolls of our training dataset\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_test = delete_url(df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with message colun void of url links\n",
    "new_df_test = delete_tags(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf021a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with all words in the message column converted to its lowercase form\n",
    "new_df_test = word_converter(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f100a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_test = remove_punc(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the message colmn void of punctuations\n",
    "new_df_test = remove_new_line(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to hold the tokens from message column\n",
    "new_df_test = tokenizer(new_df_test, 'message')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_test = stem_words(new_df_test, 'message_tok')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to hold root words from stemmer\n",
    "new_df_test = lam_words(new_df_test, 'message_tok')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f489630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column from message_lam void of stop words\n",
    "new_df_test = remove_stop_words(new_df_test, 'message_lam')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column from no_stop_word void of delimeters\n",
    "new_df_test = form_corpus(new_df_test, 'no_stop_word')\n",
    "new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ba967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop every other columns except sentiment and de_tok columns\n",
    "df_test_reduced = new_df_test[[ 'de_tok']]\n",
    "df_test_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187fac2",
   "metadata": {},
   "source": [
    "### Transform test dataset \n",
    "\n",
    "We transform the test dataset using the chosen vectorizer ***vector** from the vectorizer section above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the de_tok column\n",
    "X_count_test = vector.transform(df_test_reduced['de_tok'].values.astype(str))\n",
    "X_count_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348aaee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(data=X_count_test.toarray(),columns = vector.get_feature_names())\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d59b1",
   "metadata": {},
   "source": [
    "### Make predictions with the models generated above for kaggle submission :\n",
    "- **logreg_model** (Logistics Regression model)\n",
    "- **randomF_model** (RandomForestClasifier model)\n",
    "- **svc_model** (SVC model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c6521",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with logistics regression model and the test data\n",
    "y_pred_logistic = logreg_model.predict(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36731d44",
   "metadata": {},
   "source": [
    "#### RandomForestClasifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7580ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with RandomForestClasifier model and the test data\n",
    "y_pred_random = randomF_model.predict(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2d5df",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c453fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with RandomForestClasifier model and the test data\n",
    "y_pred_svc = svc_model.predict(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b7e1a",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88e17a",
   "metadata": {},
   "source": [
    "### Convert the predictions of the models to dataframes\n",
    "\n",
    "We have generated predictions for three different models above:\n",
    "- **y_pred_logistic** (Logistics Regression model)\n",
    "- **y_pred_random** (RandomForestClasifier model)\n",
    "- **y_pred_svc** (SVC model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf0539b",
   "metadata": {},
   "source": [
    "#### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'tweetid': df_test['tweetid'],\n",
    "    'sentiment': y_pred_logistic\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_001.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d61e9",
   "metadata": {},
   "source": [
    "#### RandomForestClasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_df = pd.DataFrame({\n",
    "    'tweetid': df_test['tweetid'],\n",
    "    'sentiment': y_pred_random\n",
    "})\n",
    "\n",
    "downsampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_df.to_csv('file_002.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96fbd9",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_df = pd.DataFrame({\n",
    "    'tweetid': df_test['tweetid'],\n",
    "    'sentiment': y_pred_svc\n",
    "})\n",
    "\n",
    "upsampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_df.to_csv('file_003.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a4499",
   "metadata": {},
   "source": [
    "### Logging Results to Comet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13998a",
   "metadata": {},
   "source": [
    "#### Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all metrics for model performance\n",
    "# f1 = f1_score(y_true, y_pred_test, average = 'weighted')\n",
    "# precision = precision_score(y_true, y_pred_test, average ='weighted')\n",
    "# recall = recall_score(y_true, y_pred_test,average = 'weighted')\n",
    "# accuracy = accuracy_score(y_true, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96baa1ad",
   "metadata": {},
   "source": [
    "### Create disctionary for data to be stored on Comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates two dictionaries, parameters and metric values\n",
    "# params = {\n",
    "#     'random_state': RANDOM_STATE,\n",
    "#     'model_type': 'Logistics Regression'\n",
    "# }\n",
    "\n",
    "# metrics ={\n",
    "#     'Accuracy': accuracy,\n",
    "#     'precision': precision,\n",
    "#     'recall': recall,\n",
    "#     'f1': f1,\n",
    "# }\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793abcfc",
   "metadata": {},
   "source": [
    "### Log parameters and metrics to commet_ml\n",
    "\n",
    "In order to adher to a fundamental pricinple of programming **DRY**(do not repeat yourself), we define a function **experiment_logger** to achieve this. This is because this is a group project with multiple comet_ml API keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_logger(experiments):\n",
    "    \"\"\"\n",
    "        This function takes in a list of comet_ml defined experiments, and logs the parameters and metric values,\n",
    "        for this notebook to the respective experiments. It has a return value of None\n",
    "    \"\"\"\n",
    "    for experiment in experiments :\n",
    "        experiment.log_parameters(params)\n",
    "        experiment.log_metrics(metrics)\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of comet experiments for this project\n",
    "# comet_experiments = [ experiment]\n",
    "\n",
    "# # Log the respective experiments parameter and metric values\n",
    "# experiment_logger(comet_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3fb7d",
   "metadata": {},
   "source": [
    "### End all comet experiment after loging the parameters\n",
    "\n",
    "To adhre to the **DRY** principle, we write a function **end_comet** to achieve this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_comet(experiments):\n",
    "    \"\"\"\n",
    "        This function takes in a list of comet_ml defined experiments, and ends the experiments.\n",
    "        It has a return value of None.\n",
    "    \"\"\"\n",
    "    for experiment in experiments :\n",
    "        experiment.end()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9335189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # End all experiments\n",
    "# end_comet(comet_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd1f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
